{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "# Load the dataset from Hugging Face if it's your first time using it\n",
    "\n",
    "# dataset = fouh.load_from_hub(\n",
    "# \"Voxel51/Coursera_lecture_dataset_train\", \n",
    "# dataset_name=\"lecture_dataset_train\", \n",
    "# persistent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because I have the dataset saved locally, I will load it like so\n",
    "cloned_dataset = fo.load_dataset(\"lecture_dataset_train_clone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #clone the dataset to avoid modifying the original dataset\n",
    "# cloned_dataset = dataset.clone(name=\"lecture_dataset_train_clone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image complexity\n",
    "\n",
    "We can use Canny edge detection to measure the ratio of edge pixels to total pixels\n",
    "\n",
    "This metric can be useful because:\n",
    "\n",
    "1. It provides a measure of the level of detail and intricacy in an image.\n",
    "\n",
    "2. Higher complexity can indicate more challenging images for object detection.\n",
    "\n",
    "3. It can help identify images that might require more processing power or sophisticated algorithms for accurate analysis.\n",
    "\n",
    "4. Understanding image complexity can aid in balancing datasets and evaluating model performance across different complexity levels.\n",
    "\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- **Oversimplification:** Edge detection reduces an image to binary information (edge or non-edge), discarding valuable texture and color information that could be crucial for object detection.\n",
    "\n",
    "- **Sensitivity to Noise:** Canny edge detection can be sensitive to image noise, potentially leading to inaccurate complexity assessments in noisy images.\n",
    "\n",
    "- **Parameter Dependency:** The effectiveness of Canny edge detection heavily relies on the chosen threshold parameters (100 and 200 in this case), which may not be optimal for all images in a diverse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_complexity(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the complexity of images in a FiftyOne dataset using Canny edge detection and color information.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (fiftyone.core.dataset.Dataset): FiftyOne dataset object.\n",
    "\n",
    "    Returns:\n",
    "    None. It just adds the field to the dataset\n",
    "    \"\"\"\n",
    "    for sample in dataset.iter_samples():\n",
    "        img = cv2.imread(sample.filepath)\n",
    "        # Convert the image to float32\n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "        # Calculate the color variance for the image\n",
    "        color_variance = np.var(img_float, axis=(0, 1)).sum()\n",
    "        # Convert to grayscale for edge detection\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        edge_complexity = np.sum(edges > 0) / (img.shape[0] * img.shape[1])\n",
    "        # Combine edge complexity and color variance\n",
    "        complexity = edge_complexity + color_variance\n",
    "        sample[\"image_complexity_score\"] = complexity\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_image_complexity(cloned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual clutter \n",
    "\n",
    "Calculates the variance of pixel intensities in the image.\n",
    "\n",
    "This metric is useful because:\n",
    "\n",
    "1. It measures the level of disorder or chaos in an image, which can impact object detection.\n",
    "\n",
    "2. High visual clutter can make it more difficult to isolate and identify individual objects.\n",
    "\n",
    "3. It provides insight into the visual complexity of scenes beyond just object count or density.\n",
    "\n",
    "4. Understanding visual clutter can help in developing strategies to improve model performance on visually complex images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_visual_clutter(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the normalized visual clutter of images in a FiftyOne dataset using pixel intensity variance and color variance.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (fiftyone.core.dataset.Dataset): FiftyOne dataset object.\n",
    "\n",
    "    Returns:\n",
    "    None. It just adds the normalized clutter score field to the dataset.\n",
    "    \"\"\"\n",
    "    max_gray_variance = 255 ** 2  # Maximum possible variance for an 8-bit grayscale image\n",
    "    max_color_variance = 3 * (1.0 ** 2)  # Maximum possible variance for colors in [0, 1]\n",
    "    max_combined_variance = max_gray_variance + max_color_variance\n",
    "\n",
    "    for sample in dataset.iter_samples():\n",
    "        img = cv2.imread(sample.filepath)\n",
    "        \n",
    "        # Calculate grayscale variance\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_clutter = np.var(gray)\n",
    "        \n",
    "        # Calculate color variance\n",
    "        img_float = img.astype(np.float32) / 255.0  # Convert to float32\n",
    "        color_variance = np.var(img_float, axis=(0, 1)).sum()\n",
    "        \n",
    "        # Combine both measures\n",
    "        clutter = gray_clutter + color_variance\n",
    "        \n",
    "        # Normalize the clutter score\n",
    "        normalized_clutter = clutter / max_combined_variance\n",
    "        \n",
    "        # Ensure the score is between 0 and 1\n",
    "        normalized_clutter = np.clip(normalized_clutter, 0, 1)\n",
    "        \n",
    "        sample[\"normalized_clutter_score\"] = float(normalized_clutter)\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_visual_clutter(cloned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Clutter\n",
    "\n",
    "An object vlutter score will identify number of detections per image. This is a simple and useful metric. It provides a quick measure of how busy or crowded an image is in terms of objects.\n",
    "\n",
    "**Pros:**\n",
    "- Easy to calculate and interpret\n",
    "- Gives a clear indication of image complexity\n",
    "\n",
    "**Cons:**\n",
    "- Doesn't account for object size or distribution\n",
    "- May not distinguish between genuinely cluttered scenes and scenes with many small objects\n",
    "\n",
    "**Usefulness:** High, especially as a basic measure of image complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_clutter_score(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the clutter score based on the number of detections per image.\n",
    "\n",
    "    This metric is useful because:\n",
    "    1. It provides a simple measure of scene complexity in terms of object count.\n",
    "    2. Higher clutter scores can indicate more challenging images for object detection.\n",
    "    3. It helps identify images that may require more processing time or have higher chances of false positives/negatives.\n",
    "    4. Understanding clutter can aid in balancing datasets and evaluating model performance across different complexity levels.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (fiftyone.core.dataset.Dataset): FiftyOne dataset object.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with image IDs as keys and clutter scores as values.\n",
    "    \"\"\"\n",
    "    clutter_scores = {}\n",
    "\n",
    "    for sample in dataset:\n",
    "        num_detections = len(sample.detections)\n",
    "        clutter_scores[sample.id] = num_detections\n",
    "\n",
    "    return clutter_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object diversity\n",
    "\n",
    "This will measure the number of distinct classes per image. This is an excellent metric for measuring the semantic diversity of an image.\n",
    "\n",
    "**Pros:**\n",
    "- Directly measures the variety of object types in an image\n",
    "- Easy to calculate and interpret\n",
    "\n",
    "**Cons:**\n",
    "- Doesn't account for the number of instances of each class\n",
    "- Treats all classes equally, regardless of their visual or semantic similarity\n",
    "\n",
    "**Usefulness:** High, particularly for understanding the range of objects a model needs to handle.\n",
    "\n",
    "3. Objectness score: % of pixels that belong to classes across the whole image\n",
    "\n",
    "This is a valuable metric for understanding how much of the image is occupied by objects of interest.\n",
    "\n",
    "**Pros:**\n",
    "- Provides insight into the density of annotated objects\n",
    "- Can help identify images with large background areas\n",
    "\n",
    "**Cons:**\n",
    "- Doesn't account for the number or diversity of objects\n",
    "- May be biased towards images with large objects\n",
    "\n",
    "**Usefulness:** High, especially when combined with other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_diversity_score(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the instance diversity based on the number of distinct classes per image.\n",
    "\n",
    "    This metric is useful because:\n",
    "    1. It quantifies the variety of object types present in an image.\n",
    "    2. Higher diversity can indicate more complex scenes that require broader object recognition capabilities.\n",
    "    3. It helps in assessing the range of objects a model needs to handle within a single image.\n",
    "    4. Understanding instance diversity can guide dataset curation to ensure a wide range of object combinations are represented.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (fiftyone.core.dataset.Dataset): FiftyOne dataset object.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with image IDs as keys and instance diversity scores as values.\n",
    "    \"\"\"\n",
    "    diversity_scores = {}\n",
    "\n",
    "    for sample in dataset:\n",
    "        unique_classes = set(det.label for det in sample.detections)\n",
    "        diversity_scores[sample.id] = len(unique_classes)\n",
    "\n",
    "    return diversity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objectness_score(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the objectness score as the percentage of pixels belonging to objects.\n",
    "\n",
    "    This metric is useful because:\n",
    "    1. It provides insight into how much of the image is occupied by objects of interest.\n",
    "    2. Lower scores might indicate images with large background areas or small objects, which can be challenging for detection.\n",
    "    3. It can help identify images where objects occupy a significant portion of the scene, potentially affecting detection strategies.\n",
    "    4. Understanding objectness can aid in analyzing model performance relative to object size and prominence in the image.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (fiftyone.core.dataset.Dataset): FiftyOne dataset object.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with image IDs as keys and objectness scores as values.\n",
    "    \"\"\"\n",
    "    objectness_scores = {}\n",
    "\n",
    "    for sample in dataset:\n",
    "        total_pixels = sample.metadata.width * sample.metadata.height\n",
    "        object_pixels = sum(det.bounding_box[2] * det.bounding_box[3] * total_pixels\n",
    "                            for det in sample.detections)\n",
    "        objectness_scores[sample.id] = object_pixels / total_pixels\n",
    "\n",
    "    return objectness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Diversity Ratio\n",
    "\n",
    "This metric considers the number of detections and number of classes per image\n",
    "\n",
    "This is a more nuanced approach to measuring diversity that takes into account both the number of objects and the variety of classes.\n",
    "\n",
    "**Pros:**\n",
    "- Combines quantity and variety of objects\n",
    "- Can distinguish between images with many objects of few classes and those with fewer objects but more classes\n",
    "\n",
    "**Cons:**\n",
    "- May require careful design to balance the influence of object count and class count\n",
    "- Interpretation might be less intuitive than simpler metrics\n",
    "\n",
    "**Usefulness:** High, as it provides a more comprehensive view of image complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diversity_ratio(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the diversity ratio considering both number of detections and classes.\n",
    "\n",
    "    This metric is useful because:\n",
    "    1. It balances the number of objects with the variety of object types, providing a more nuanced view of image complexity.\n",
    "    2. It can distinguish between images with many objects of few classes and those with fewer objects but more diverse classes.\n",
    "    3. Higher ratios might indicate images that require broader object recognition capabilities.\n",
    "    4. This metric can help in creating balanced datasets that challenge models in different ways.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (fiftyone.core.dataset.Dataset): FiftyOne dataset object.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with image IDs as keys and diversity ratio scores as values.\n",
    "    \"\"\"\n",
    "    diversity_ratios = {}\n",
    "\n",
    "    for sample in dataset:\n",
    "        num_detections = len(sample.detections)\n",
    "        num_classes = len(set(det.label for det in sample.detections))\n",
    "        if num_detections > 0:\n",
    "            diversity_ratios[sample.id] = num_classes / np.log(num_detections + 1)\n",
    "        else:\n",
    "            diversity_ratios[sample.id] = 0\n",
    "\n",
    "    return diversity_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
