{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import plugins\n",
    "\n",
    "plugins.download_plugin(\n",
    "    url_or_gh_repo=\"https://github.com/voxel51/fiftyone_mlflow_plugin/\"\n",
    ")\n",
    "\n",
    "plugins.install_plugin_requirements(\n",
    "    plugin_name=\"@voxel51/mlflow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for Training\n",
    "\n",
    "Let's kick things off by loading in all of our required libraries. While we are at it, we will start our MLflow client and specifying our `tracking_uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://127.0.0.1:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(\"lecture_dataset_train\")\n",
    "\n",
    "dataset = dataset.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "sample_size = 0.051  # adjust as needed\n",
    "\n",
    "class_counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "\n",
    "class_samples = {cls: int(count * sample_size) for cls, count in class_counts.items()}\n",
    "\n",
    "stratified_sample = fo.Dataset() # instantiate an empty dataset\n",
    "stratified_sample.default_classes = dataset.default_classes # copy the default classes from the original dataset\n",
    "\n",
    "for label, sample_count in class_samples.items():\n",
    "    existing_ids = stratified_sample.values(\"id\") # list of ids for samples already added\n",
    "    filter_expression = F(\"label\") == label \n",
    "    class_view = dataset.match_labels(filter = filter_expression, fields=\"ground_truth\", bool=True)\n",
    "    subset_view = class_view.take(sample_count, seed=51) # take a random sample of the view\n",
    "    stratified_sample.add_samples(subset_view.exclude(existing_ids)) #add the samples in the view to the stratified_sample dataset\n",
    "    stratified_sample.shuffle(seed=51) # shuffle the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset based on image quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.operators as foo\n",
    "\n",
    "compute_brightness = foo.get_operator(\n",
    "    \"@jacobmarks/image_issues/compute_brightness\"\n",
    ")\n",
    "\n",
    "compute_brightness(stratified_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_bright_value = stratified_sample.mean(\"brightness\") + 3 * stratified_sample.std(\"brightness\")\n",
    "\n",
    "brightness_filter = F(\"brightness\") < too_bright_value\n",
    "\n",
    "brightness_filtered_view = stratified_sample.match(brightness_filter) \n",
    "\n",
    "brightness_filtered_dataset = brightness_filtered_view.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(brightness_filtered_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export FiftyOne Dataset to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training config\n",
    "import yaml\n",
    "\n",
    "config_path = '/home/harpreet/workspace/Hands-on-Data-Centric-Visual-AI/training_helpers/training_config.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    training_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four.random_split(brightness_filtered_dataset, {\"train\": training_config['train_split'], \"val\": training_config['val_split']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_filtered_dataset.export(\n",
    "    export_dir=\"./model_training/data\",\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    classes=brightness_filtered_dataset.default_classes,\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_filtered_dataset.export(\n",
    "    export_dir=\"./model_training/data\",\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    classes=brightness_filtered_dataset.default_classes,\n",
    "    split= 'val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the MLflow Server\n",
    "Before we begin, we will start our MLflow server locally to serve as our backend for the demo. Open the terminal and enter the following the same project directory:\n",
    "\n",
    "```\n",
    "mlflow server --backend-store-uri model_training/runs/mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.operators as foo\n",
    "from ultralytics import YOLO, settings\n",
    "\n",
    "settings.update({\"mlflow\": True})\n",
    "\n",
    "EXPERIMENT_NAME = \"model_training/brightness_filtered\"\n",
    "RUN_NAME = \"run-1\"\n",
    "LABEL_FIELD = \"predictions\" \n",
    "\n",
    "log_mlflow_run = foo.get_operator(\"@voxel51/mlflow/log_mlflow_run\")\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data = \"./model_training/data/dataset.yaml\",\n",
    "    project=EXPERIMENT_NAME,\n",
    "    name=RUN_NAME,\n",
    "    **training_config['train_params']\n",
    ")\n",
    "\n",
    "log_mlflow_run(\n",
    "    brightness_filtered_dataset, \n",
    "    EXPERIMENT_NAME, \n",
    "    run_name=RUN_NAME, \n",
    "    predictions_field=LABEL_FIELD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dataset.evaluate_detections(pred_field=\"predictions\", gt_field=\"ground_truth\", eval_key=\"eval\", compute_mAP=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
