{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "# Load the dataset from Hugging Face if it's your first time using it\n",
    "\n",
    "# dataset = fouh.load_from_hub(\n",
    "#     \"Voxel51/Coursera_lecture_dataset_train\", \n",
    "#     dataset_name=\"lecture_dataset_train\", \n",
    "#     persistent=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because I have the dataset saved locally, I will load it like so\n",
    "cloned_dataset = fo.load_dataset(\"lecture_dataset_train_clone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar images (near duplicates)\n",
    "\n",
    "Removing duplicates and near-duplicates can improve model training by avoiding accidental concept imbalance. Duplicated data is a common problem in dataset creation and can be challenging to identify, especially when small data manipulations have occurred. For model training workflows, it's crucial to maximize the value of each data sample. Near-duplicates, which are very similar samples, are inherently less valuable for training models.\n",
    "\n",
    "The FiftyOne Brain's [`compute_similarity`](https://docs.voxel51.com/api/fiftyone.brain.html#fiftyone.brain.compute_similarity) method indexes images or object patches by similarity. This allows you to:\n",
    "\n",
    "1. Find similar examples to diagnose model failures\n",
    "2. Mine data to augment training sets\n",
    "3. Use `sort_by_similarity` to programmatically sort datasets by similarity to chosen images or patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "similarity_index = fob.compute_similarity(\n",
    "    samples=cloned_dataset,\n",
    "    embeddings=\"mobilenet_v2_embeddings\",\n",
    "    backend=\"sklearn\",\n",
    "    brain_key=\"mobilenet_similarity\",\n",
    "    metric=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use [`sort_by_similarity`](https://docs.voxel51.com/api/fiftyone.brain.html#fiftyone.brain.compute_similarity) in the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some random id from the dataset\n",
    "\n",
    "query_id = cloned_dataset.take(1).first().id\n",
    "\n",
    "similarity_view = similarity_index.sort_by_similarity(query_id, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(similarity_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use our similarity index to detect near-duplicate images in the dataset. For example, let’s use the [`find_duplicates`](https://docs.voxel51.com/api/fiftyone.brain.similarity.html#fiftyone.brain.similarity.DuplicatesMixin.find_duplicates) method to identify the least similar images in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_index.find_duplicates(fraction=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `neighbors_map` property in the `similarity_index` object summarizes the results. It contains keys representing the sample IDs of the nearest non-duplicate images and values consisting of lists of `(id, distance)` tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarity_index.neighbors_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing `fraction` into the function it's the desired fraction of images/patches to tag as duplicates, in [0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_index.find_duplicates(fraction=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view this information in the app using the [`duplicates_view`](https://docs.voxel51.com/api/fiftyone.brain.similarity.html#fiftyone.brain.similarity.DuplicatesMixin.duplicates_view) method, which arranges duplicate images next to their corresponding nearest in-sample image, along with additional fields for image type and nearest in-sample ID/distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_view = similarity_index.duplicates_view(\n",
    "    type_field=\"dup_type\",\n",
    "    id_field=\"dup_id\",\n",
    "    dist_field=\"dup_dist\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(duplicates_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also provide a specific embeddings distance threshold (via the `thresh` parameter) to `find_duplicates`, in which case the non-duplicate set will be the (approximately) largest set such that all pairwise distances between non-duplicate images are greater than this threshold, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_index.find_duplicates(thresh=0.51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exact duplicates\n",
    "\n",
    "This method identifies exact duplicates using the same filehash. If duplicates are found, the first instance becomes the key in the returned dictionary, with subsequent duplicates as the corresponding list values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "import os \n",
    "\n",
    "fob.compute_exact_duplicates(\n",
    "    samples=cloned_dataset,\n",
    "    num_workers=os.cpu_count(),\n",
    "    progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_dups = cloned_dataset.select(['66a2f304ce2f9d11d9a17adc','66a2f315ce2f9d11d9a1a706'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(exact_dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique images\n",
    "\n",
    "Identifying the most unique samples helps in creating a high-quality, diverse training set.\n",
    "\n",
    "This function adds a uniqueness score to each sample based on its distinctiveness from other samples. It processes pixel data and can handle labeled or unlabeled samples. If embeddings or a model are not provided, a default model is used to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "import os \n",
    "\n",
    "fob.compute_uniqueness(\n",
    "    samples=cloned_dataset,\n",
    "    embeddings=\"mobilenet_v2_embeddings\",\n",
    "    num_workers=os.cpu_count(),\n",
    "    progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by uniqueness (most unique first)\n",
    "dups_view = cloned_dataset.sort_by(\"uniqueness\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the deduplication plugin\n",
    "\n",
    "As we've discussed in this lesson, creating a high-quality dataset for training machine learning models is challenging due to duplicate or similar data.  We've seen that duplicates come in two flavours:\n",
    "\n",
    "1. **Exact duplicates:** pixel-perfect matches, where one image is a down-to-the-bit copy of another\n",
    "\n",
    "2. **Approximate duplicates:** When evaluating images or other data for similarity, a threshold is set based on a similarity metric used to measure the closeness between samples.\n",
    "\n",
    "Deduplication is the task of removing these exact and approximate duplicates from a dataset. \n",
    "\n",
    "With the [Image Deduplication Plugin](https://github.com/jacobmarks/image-deduplication-plugin), you can deduplicate your entire dataset from within the FiftyOne App, without writing any code. This plugin makes it easy to:\n",
    "\n",
    "- Identify exact duplicates using hash functions\n",
    "\n",
    "- Detect near-duplicates using embedding models and similarity thresholds\n",
    "\n",
    "- Interactively view duplicate images in the FiftyOne App\n",
    "\n",
    "- Options to remove all duplicates or retain representative images\n",
    "\n",
    "## Main Operators\n",
    "\n",
    "**Duplicate Detection:**\n",
    "\n",
    "- `find_approximate_duplicate_images`: Locates near-duplicate images using similarity indices\n",
    "\n",
    "- `find_exact_duplicate_images`: Identifies exact duplicates using hash functions\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "- `display_approximate_duplicate_groups`: Shows groups of near-duplicate images\n",
    "\n",
    "- `display_exact_duplicate_groups`: Presents groups of exact duplicate images\n",
    "\n",
    "**Duplicate Removal:**\n",
    "\n",
    "- `remove_all_approximate_duplicates`: Eliminates all near-duplicate images\n",
    "\n",
    "- `remove_all_exact_duplicates`: Removes all exact duplicate images\n",
    "\n",
    "**Selective Deduplication:**\n",
    "\n",
    "- `deduplicate_approximate_duplicates`: Removes near-duplicates while keeping representative images\n",
    "\n",
    "- `deduplicate_exact_duplicates`: Eliminates exact duplicates while retaining representative images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import plugins\n",
    "\n",
    "plugins.download_plugin(\n",
    "    url_or_gh_repo=\"https://github.com/jacobmarks/image-deduplication-plugin\"\n",
    ")\n",
    "\n",
    "plugins.install_plugin_requirements(\n",
    "    plugin_name=\"@jacobmarks/image_deduplication\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, what we've discussed here can be done on the patches level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
