{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you haven't already set up your environment, install the following:\n",
    "# pip install fiftyone umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "# Load the dataset from Hugging Face if it's your first time using it\n",
    "\n",
    "# dataset = fouh.load_from_hub(\n",
    "#     \"Voxel51/Coursera_lecture_dataset_train\", \n",
    "#     dataset_name=\"lecture_dataset_train\", \n",
    "#     persistent=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because I have the dataset saved locally, I will load it like so\n",
    "cloned_dataset = fo.load_dataset(\"lecture_dataset_train_clone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make use of the outlier detection plugin. You can find more information about that [here](https://github.com/danielgural/outlier_detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import plugins\n",
    "\n",
    "plugins.download_plugin(\n",
    "    url_or_gh_repo=\"https://github.com/danielgural/outlier_detection\"\n",
    ")\n",
    "\n",
    "plugins.install_plugin_requirements(\n",
    "    plugin_name=\"@danielgural/outlier_detection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FiftyOne has a [model zoo](https://docs.voxel51.com/user_guide/model_zoo/models.html) with 100+ models that you can use. Many of which expose embeddings. \n",
    "\n",
    "For this lesson, we'll load a simple MobileNetV2 model from the zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "model = foz.load_zoo_model(\n",
    "    \"mobilenet-v2-imagenet-torch\",\n",
    "    # device=\"cuda\" # if you're running this on a GPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this model to compute embeddings for all images in the dataset, note that this could take 10-15 minutes (if you're running on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "embeddings = cloned_dataset.compute_embeddings(\n",
    "    model,\n",
    "    embeddings_field=\"mobilenet_v2_embeddings\",\n",
    "    progress=True,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.first()['mobilenet_v2_embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can perform [dimensionality reduction](https://docs.voxel51.com/tutorials/dimension_reduction.html) so you can visualize the images in the app. \n",
    "\n",
    "For this, we'll use the `compute_visualization` method of [FiftyOne Brain](https://docs.voxel51.com/user_guide/brain.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_visualization(\n",
    "    cloned_dataset,\n",
    "    embeddings='mobilenet_v2_embeddings',\n",
    "    brain_key='mobile_net_viz',\n",
    "    num_dims=2,\n",
    "    method='umap'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compute embeddings on a patch basis, note you can also compute embeddings and visualizations directly with `compute_visualizations`. Note, we're computing embeddings for each detection, so this process can take a **long** time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = cloned_dataset.take(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fob.compute_visualization(\n",
    "    samples=sampled_dataset,\n",
    "    patches_field=\"ground_truth\",\n",
    "    model=model,\n",
    "    brain_key=\"patch_embeddings\",\n",
    "    method=\"umap\",\n",
    "    num_dims=2,\n",
    "    num_workers=os.cpu_count(),\n",
    "    progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_view = sampled_dataset.to_patches(\"ground_truth\", other_fields=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(patches_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the outlier detection plugin for the app. \n",
    "\n",
    "This plugin uses the Local Outlier Factor (LOF). This is a anomaly detection method that:\n",
    "\n",
    "1. Measures the local density deviation of a sample compared to its neighbors.\n",
    "\n",
    "2. Uses k-nearest neighbors to define locality and estimate local density.\n",
    "\n",
    "3. Identifies outliers by comparing a sample's local density to that of its neighbors.\n",
    "\n",
    "4. Assigns higher anomaly scores to samples with substantially lower density than their surrounding area.\n",
    "\n",
    "5. Provides a localized approach to outlier detection, sensitive to the sample's immediate neighborhood context.\n",
    "\n",
    "You can learn more about LOF [here](https://machinelearninginterview.com/topics/machine-learning/local-outlier-factor-lof/) and [here](https://detectoutliers.com/2023/03/24/using-the-local-outlier-factor-lof-for-unsupervised-anomaly-detection/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Required reading:\n",
    "\n",
    "- [Using Image Embeddings](https://docs.voxel51.com/tutorials/image_embeddings.html)\n",
    "\n",
    "- [How to Visualize Your Data with Dimension Reduction Techniques](https://voxel51.com/blog/how-to-visualize-your-data-with-dimension-reduction-techniques/)\n",
    "\n",
    "- [Computer Vision Embedding Tips and Tricks](https://medium.com/voxel51/fiftyone-computer-vision-embeddings-tips-and-tricks-mar-31-2023-625b9d9202cd)\n",
    "\n",
    "- [Finding Outliers in Your Vision Dataset](https://medium.com/voxel51/finding-outliers-in-your-vision-datasets-9bc1d806838c)\n",
    "\n",
    "\n",
    "If you ever need assistance, have more complex questions, or want to keep in touch, feel free to join the Voxel51 community Discord server [here](https://discord.gg/QAyfnUhfpw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
