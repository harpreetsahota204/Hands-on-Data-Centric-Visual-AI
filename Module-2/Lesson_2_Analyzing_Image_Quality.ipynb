{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "# Load the dataset from Hugging Face if it's your first time using it\n",
    "\n",
    "# dataset = fouh.load_from_hub(\n",
    "#     \"Voxel51/Coursera_lecture_dataset_train\", \n",
    "#     dataset_name=\"lecture_dataset_train\", \n",
    "#     persistent=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because I have the dataset saved locally, I will load it like so\n",
    "cloned_dataset = fo.load_dataset(\"lecture_dataset_train_clone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the [Image Quality Issues](https://github.com/jacobmarks/image-quality-issues) plugin in FiftyOne to find common issues in your image dataset.\n",
    "\n",
    "With this plugin, you can find the following issues:\n",
    "\n",
    "- **üìè Aspect ratio (`compute_aspect_ratio`):** find images with weird aspect ratios\n",
    "\n",
    "- **üå´Ô∏è Blurriness (`compute_blurriness`):** find blurry images\n",
    "\n",
    "- **‚òÄÔ∏è Brightness (`compute_brightness`):** find bright and dark images\n",
    "\n",
    "- **üåì Contrast (`compute_contrast`):** find images with high or low contrast\n",
    "\n",
    "- **üîÄ Entropy (`compute_entropy`):** find images with low entropy\n",
    "\n",
    "- **üì∏ Exposure (`compute_exposure`):** find overexposed and underexposed images\n",
    "\n",
    "- **üïØÔ∏è Illumination (`compute_vignetting`):** find images with uneven illumination\n",
    "\n",
    "- **üßÇ Noise (`compute_salt_and_pepper`):** find images with high salt and pepper noise\n",
    "\n",
    "- **üåà Saturation (`compute_saturation`):** find images with low and high saturation\n",
    "\n",
    "To make use of the plugin, you'll need to install it and install it's requirements:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the plugin:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import plugins\n",
    "\n",
    "plugins.download_plugin(\n",
    "    url_or_gh_repo=\"https://github.com/jacobmarks/image-quality-issues/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins.list_downloaded_plugins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins.install_plugin_requirements(\n",
    "    plugin_name=\"@jacobmarks/image_issues\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the plugin and it's dependencies installed, you can use the plugin directly through the app or via the SDK.  When using the plugin via the SDK, you'll use it as an Operator. In FiftyOne, an Operator is a user-facing operation that allows you to interact with the data in your dataset. \n",
    "\n",
    "You access the opeartor via it's URL (plugin name + operator name):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.operators as foo\n",
    "\n",
    "compute_brightness = foo.get_operator(\n",
    "    \"@jacobmarks/image_issues/compute_brightness\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the `compute_brightness` operator executes a function that takes an image and [calculates how bright it appears to the human eye](https://www.nbdtech.com/Blog/archive/2008/04/27/calculating-the-perceived-brightness-of-a-color.aspx). It does this by looking at the colors in the image and applying a formula that mimics how our eyes perceive brightness.\n",
    "\n",
    "The function considers that our eyes are more sensitive to some colors than others. For example, we perceive green as brighter than blue, even if they have the same intensity. The function takes this into account when calculating the overall brightness of the image.\n",
    "\n",
    "In simple terms, it's like the function is \"squinting\" at the image and giving it a single number that represents how bright the image looks overall. This can be useful for things like automatically adjusting image contrast or identifying images that might be too dark or too bright.\n",
    "\n",
    "You can apply the `compute_brightness` operator to the entire dataset, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_brightness(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the dataset now has a field called `brightness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset in the app: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset=cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the SDK to get some more insight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.bounds(\"brightness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.std(\"brightness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.mean(\"brightness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.quantiles(\"brightness\", quantiles=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create also construct a view of images based on some threshold value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "low_brightness_view = cloned_dataset.filter_field(\"brightness\", F() < 0.3214)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compute image quality metrics on the patch level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_brightness(cloned_dataset, patches_field=\"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then create a patches view of dataset and perform analysis on a detection level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_view = cloned_dataset.to_patches(\"ground_truth\", other_fields=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglasses_patches = patches_view.filter_labels(\"ground_truth\", F(\"label\")==\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(sunglasses_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPEG Compression\n",
    "\n",
    "To compute a metric for quantifying JPEG compression.\n",
    "\n",
    "We'll write code that exploits the fact that JPEG compression tends to create noticeable differences at the edges of 8x8 pixel blocks, especially at higher compression levels. By comparing these block-edge differences to general pixel differences across the image, it can estimate how much compression has been applied.\n",
    "\n",
    "We can implement the following functions:\n",
    "\n",
    "1. `compute_channel_metric`:\n",
    "   This function analyzes a single color channel of an image to detect JPEG compression artifacts. It does this by:\n",
    "   - Calculating average differences between adjacent pixels horizontally and vertically.\n",
    "   - Calculating average differences between pixels at the edges of 8x8 blocks (JPEG uses 8x8 pixel blocks for compression).\n",
    "   - Comparing these differences to detect the presence of blocking artifacts.\n",
    "   - The function will work with images of any size, including those not divisible by 8.\n",
    "\n",
    "2. `estimate_jpeg_quality`:\n",
    "   This function estimates the overall JPEG compression level of an image by:\n",
    "   - Reading the image and converting it to the YCrCb color space (Y: luminance, Cr and Cb: chrominance).\n",
    "   - Applying the `compute_channel_metric` to each channel (Y, Cr, Cb) separately.\n",
    "   - Combining these metrics with a weighted average, giving more importance to the luminance channel as it's more perceptually significant to human vision.\n",
    "\n",
    "The resulting metric is a single floating-point number where higher values indicate more compression artifacts (and thus, lower image quality). This metric is relative and most useful for comparing different images or different versions of the same image, rather than as an absolute measure of quality.\n",
    "\n",
    "- Lower values (closer to 0) suggest less compression and higher image quality.\n",
    "- Higher values suggest more compression artifacts and lower image quality.\n",
    "- Very low values (e.g., < 0.1) might indicate an image with very little compression.\n",
    "- Very high values (e.g., > 1.5) might indicate heavy compression with noticeable artifacts.\n",
    "\n",
    "Factors affecting the metric:\n",
    "\n",
    " - **Image content:** Smooth areas tend to compress better than areas with lots of detail.\n",
    "\n",
    " - **Original image quality:** Starting with a higher quality image generally results in a lower metric even after compression.\n",
    "\n",
    " - **Compression algorithm:** Different JPEG encoders might produce slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def compute_channel_metric(channel):\n",
    "    \"\"\"\n",
    "    Compute quality metric for a single channel, handling any image size.\n",
    "\n",
    "    Args:\n",
    "        channel (numpy.ndarray): 2D array representing an image channel.\n",
    "\n",
    "    Returns:\n",
    "        float: Quality metric for the channel.\n",
    "    \"\"\"\n",
    "    height, width = channel.shape\n",
    "    \n",
    "    # Compute general pixel differences\n",
    "    diff_h = np.abs(channel[:, 1:] - channel[:, :-1]).mean()\n",
    "    diff_v = np.abs(channel[1:, :] - channel[:-1, :]).mean()\n",
    "    \n",
    "    # Compute block differences, adjusting for image size\n",
    "    block_size = 8\n",
    "    h_blocks = (height - 1) // block_size\n",
    "    w_blocks = (width - 1) // block_size\n",
    "    \n",
    "    if h_blocks > 0 and w_blocks > 0:\n",
    "        diff_h_block = np.abs(channel[:, block_size::block_size] - \n",
    "                              channel[:, block_size-1:-1:block_size]).mean()\n",
    "        diff_v_block = np.abs(channel[block_size::block_size, :] - \n",
    "                              channel[block_size-1:-1:block_size, :]).mean()\n",
    "    else:\n",
    "        # Fallback for very small images\n",
    "        diff_h_block = diff_h\n",
    "        diff_v_block = diff_v\n",
    "    \n",
    "    # Compute relative differences\n",
    "    rel_diff_h = diff_h_block / (diff_h + 1e-6)  # Avoid division by zero\n",
    "    rel_diff_v = diff_v_block / (diff_v + 1e-6)\n",
    "    \n",
    "    return (rel_diff_h + rel_diff_v) / 2\n",
    "\n",
    "def estimate_jpeg_quality(image_path):\n",
    "    \"\"\"\n",
    "    Estimate the JPEG compression level of an image based on blocking artifacts,\n",
    "    considering both luminance and chrominance information.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the JPEG image file.\n",
    "\n",
    "    Returns:\n",
    "        float: A metric representing the estimated compression level.\n",
    "               Higher values indicate more compression.\n",
    "    \"\"\"\n",
    "    # Read the image in color\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Unable to read image at {image_path}\")\n",
    "\n",
    "    # Convert to YCrCb color space\n",
    "    img_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Split into Y, Cr, and Cb channels\n",
    "    y, cr, cb = cv2.split(img_ycrcb)\n",
    "\n",
    "    # Compute metrics for each channel\n",
    "    y_metric = compute_channel_metric(y)\n",
    "    cr_metric = compute_channel_metric(cr)\n",
    "    cb_metric = compute_channel_metric(cb)\n",
    "\n",
    "    # Weighted average of channel metrics\n",
    "    # We give more weight to luminance (Y) as it's more perceptually important\n",
    "    final_metric = 0.6 * y_metric + 0.2 * cr_metric + 0.2 * cb_metric\n",
    "\n",
    "    return final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = cloned_dataset.values(\"filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_compression_scores = [estimate_jpeg_quality(fp) for fp in image_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.set_values(\"estimated_compression_score\", estimated_compression_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.bounds(\"estimated_compression_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `find_issues` operator (only through the app), which allows you to designate images (or detections) as plagued by specific issues. \n",
    "\n",
    "You can run the issue-finding operator in single-issue or multi-issue mode, and can specify the threshold for each issue at the time of execution. \n",
    "\n",
    "All necessary computations which have not yet been run will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(cloned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the images will have a tag indicating the issues present:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_dataset.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you ever need assistance, have more complex questions, or want to keep in touch, feel free to join the Voxel51 community Discord server [here](https://discord.gg/QAyfnUhfpw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
